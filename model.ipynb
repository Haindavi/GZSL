{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from itertools import chain\n",
    "\n",
    "class GZSL(nn.Module):\n",
    "    def __init__(self,feat_dim, cls_dim, enc_hdim1, enc_hdim2, zdim, dec_hdim1, disc_hdim1\n",
    " ):\n",
    "        super(GZSL, self).__init__()\n",
    "          \n",
    "        self.feat_dim = feat_dim #2048 img feat size\n",
    "        self.cls_dim = cls_dim #85 clas attribute vector dim\n",
    "        self.enc_hdim1 =enc_hdim1 # 512 first hidden layer in encoder\n",
    "        self.enc_hdim2 =enc_hdim2 # 512 second hidden layer in encoder\n",
    "        self.zdim = zdim # 512 second hidden layer in encoder\n",
    "        self.dec_hdim1 = dec_hdim1 # hidden layer in decoder\n",
    "        self.disc_hdim1 = disc_hdim1 # hidden layer in decoder\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(disc_hdim1)\n",
    "\n",
    "\n",
    "\n",
    "        #define encoder layers\n",
    "        self.enc_lin1 = nn.Linear(self.feat_dim + self.cls_dim, self.enc_hdim1)\n",
    "        self.enc_lin2 = nn.Linear(self.enc_hdim1, self.enc_hdim2)\n",
    "        self.mu = nn.Linear(self.enc_hdim2, self.zdim)\n",
    "        self.log_sigma = nn.Linear(self.enc_hdim2, self.zdim)\n",
    "        self.dp = nn.Dropout(p=0.3)\n",
    "\n",
    "        #define decoder layers\n",
    "        self.dec_lin1 = nn.Linear(self.zdim + self.cls_dim,self.dec_hdim1)\n",
    "        self.dec_lin2 = nn.Linear(self.dec_hdim1, self.feat_dim)\n",
    "        \n",
    "        #define discriminator layers\n",
    "        self.disc_lin1 = nn.Linear(self.feat_dim, self.disc_hdim1)\n",
    "        self.disc_lin2 = nn.Linear(self.disc_hdim1, self.cls_dim)\n",
    "        \n",
    "        #Grouping the model's parameters: separating encoder, decoder, and discriminator\n",
    "        self.enc_params = chain(\n",
    "            self.enc_lin1.parameters(), self.enc_lin2.parameters(),\n",
    "            self.mu.parameters(), self.log_sigma.parameters()\n",
    "        )\n",
    "        self.dec_params = chain(\n",
    "            self.dec_lin1.parameters(), self.dec_lin2.parameters()\n",
    "        )\n",
    "        self.disc_params = chain(\n",
    "            self.disc_lin1.parameters(), self.disc_lin2.parameters()\n",
    "        )\n",
    "        self.vae_params = chain(\n",
    "            self.enc_params, self.dec_params\n",
    "        )\n",
    "        \n",
    "        # filter parameters that dont need grad back prop\n",
    "        self.vae_params = filter(lambda p: p.requires_grad, self.vae_params)\n",
    "        self.disc_params = filter(lambda p: p.requires_grad, self.disc_params)\n",
    "\n",
    "    def forward_encoder(self, inputs):\n",
    "        out_lin1 = self.enc_lin1(inputs)        \n",
    "        act_lin1 = self.dp(F.relu(out_lin1))\n",
    "        out_lin2 = F.relu(self.enc_lin2(act_lin1))\n",
    "        mu_out = self.mu(out_lin2)\n",
    "        log_sigma_out = self.log_sigma(out_lin2)\n",
    "        return mu_out, log_sigma_out\n",
    "\n",
    "    def forward_decoder(self,z,c):\n",
    "        inputs = torch.cat((z.view(-1,50),c.view(-1,85)),1)\n",
    "        out_lin1 = F.relu(self.dec_lin1(inputs))\n",
    "        out_lin2 = self.dec_lin2(out_lin1)\n",
    "        return out_lin2\n",
    "    \n",
    "    def forward_discriminator(self, inputs):\n",
    "        out_lin1 = F.relu(self.disc_lin1(inputs))\n",
    "        out_lin2 = self.disc_lin2(out_lin1)\n",
    "        return out_lin2\n",
    "        \n",
    "\n",
    "    def sample_z(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        Reparameterization trick: z = mu + std*eps; eps ~ N(0, I)\n",
    "        \"\"\"\n",
    "        eps = Variable(torch.randn(self.zdim))\n",
    "        return mu + torch.exp(logvar/2) * eps    \n",
    "        \n",
    "    def forward(self, img_feat, cls_feat, use_c_prior=True):\n",
    "     \n",
    "        self.train()\n",
    "\n",
    "        enc_in = torch.cat((img_feat,cls_feat),1)\n",
    "        mu, logvar = self.forward_encoder(enc_in)\n",
    "\n",
    "        z = self.sample_z(mu, logvar)    \n",
    "         \n",
    "        if use_c_prior:\n",
    "            c = cls_feat   \n",
    "        else:\n",
    "            c = self.forward_discriminator(img_feat)\n",
    "            \n",
    "        y = self.forward_decoder(z, c)\n",
    "        recon_loss = F.mse_loss(y.view(-1, self.feat_dim), img_feat.view(-1,self.feat_dim), size_average=True)\n",
    "        kl_loss = torch.mean(0.5 * torch.sum(torch.exp(logvar) + mu**2 - 1 - logvar, 1))\n",
    "        return recon_loss, kl_loss\n",
    "\n",
    "    def generate_images(self, batch_size,cls_attr):\n",
    "        samples = []\n",
    "        cs = cls_attr\n",
    "        for i in range(batch_size):\n",
    "            z = self.sample_z_prior(1) \n",
    "            c= cls_attr[i]\n",
    "            samples.append(self.sample_img(z, c))\n",
    "\n",
    "        X_gen = torch.cat(samples, dim=0)\n",
    "      \n",
    "        return X_gen, cls_attr\n",
    "\n",
    "    def sample_img(self, z, c):\n",
    "        self.eval()\n",
    "        out = self.forward_decoder(z,c)\n",
    "        self.train()\n",
    "        return out\n",
    "\n",
    "    def sample_z_prior(self, mbsize):\n",
    "        \"\"\"\n",
    "        Sample z ~ p(z) = N(0, I)\n",
    "        \"\"\"\n",
    "        z = Variable(torch.randn(mbsize, self.zdim))\n",
    "        return z        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
